{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# for tensorflow\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow.keras.backend as K\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "# other usefull library\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "from os.path import join as pjoin\r\n",
    "from datetime import datetime\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import collections\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path_drive = \"gdrive/My Drive/ColabNotebooks/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def split_train_val(args, per_val=0.1):\r\n",
    "    \"\"\"\r\n",
    "    Separa a base em treino e validação\r\n",
    "    :parâmetro args: argumentos \r\n",
    "    :parâmetro per_val: representar a proporção do conjunto de dados a ser incluído na divisão de validação (entre 0,0 e 1,0)\r\n",
    "    \"\"\"\r\n",
    "    # create inline and crossline sections for training and validation:\r\n",
    "    loader_type = 'section'\r\n",
    "    labels = np.load(pjoin((path_drive + 'data'), 'train', 'train_labels.npy'))\r\n",
    "    \r\n",
    "    i_list = list(range(labels.shape[0]))\r\n",
    "    i_list = ['i_'+str(inline) for inline in i_list]\r\n",
    "    \r\n",
    "    x_list = list(range(labels.shape[1]))\r\n",
    "    x_list = ['x_'+str(crossline) for crossline in x_list]\r\n",
    "    \r\n",
    "    list_train_val = i_list + x_list\r\n",
    "    \r\n",
    "    # create train and test splits:\r\n",
    "    list_train, list_val = train_test_split(\r\n",
    "        list_train_val, test_size=per_val, shuffle=True)\r\n",
    "\r\n",
    "    #write to files to disK:\r\n",
    "    file_object = open(pjoin((path_drive + 'data'), 'splits', loader_type + '_train_val.txt'), 'w')\r\n",
    "    file_object.write('\\n'.join(list_train_val))\r\n",
    "    file_object.close()\r\n",
    "    file_object = open(pjoin((path_drive + 'data'), 'splits', loader_type + '_train.txt'), 'w')\r\n",
    "    file_object.write('\\n'.join(list_train))\r\n",
    "    file_object.close()\r\n",
    "    file_object = open(pjoin((path_drive + 'data'), 'splits', loader_type + '_val.txt'), 'w')\r\n",
    "    file_object.write('\\n'.join(list_val))\r\n",
    "    file_object.close()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class section_loader():\r\n",
    "\t\"\"\"\r\n",
    "\tData loader for the section-based deconvnet\r\n",
    "\t\"\"\"\r\n",
    "\tdef __init__(self, split='train', is_transform=True, augmentations=None):      \r\n",
    "\t\t\"\"\"\r\n",
    "\t\tInicializa os parâmetros da classe\r\n",
    "\t\t:parâmetro split: argumentos \r\n",
    "\t\t:parâmetro is_transform: argumentos \r\n",
    "\t\t:parâmetro augmentations:  \r\n",
    "\t\t\"\"\"      \r\n",
    "\t\tdata = path_drive + 'data/' #path\r\n",
    "\t\tself.root = data\r\n",
    "\t\tself.split = split\r\n",
    "\t\tself.is_transform = is_transform\r\n",
    "\t\tself.augmentations = augmentations\r\n",
    "\t\tself.n_classes = 6 \r\n",
    "\t\tself.mean = 0.000941 # average of the training data  \r\n",
    "\t\tself.sections = collections.defaultdict(list)\r\n",
    "\r\n",
    "\t\tif 'test' not in self.split: \r\n",
    "\t\t\t# Normal train/val mode\r\n",
    "\t\t\tself.seismic = np.load(pjoin((path_drive + 'data'),'train','train_seismic.npy'))\r\n",
    "\t\t\tself.labels = np.load(pjoin((path_drive + 'data'),'train','train_labels.npy'))\r\n",
    "\t\telif 'test1' in self.split:\r\n",
    "\t\t\tself.seismic = np.load(pjoin((path_drive + 'data'),'test_once','test1_seismic.npy'))\r\n",
    "\t\t\tself.labels = np.load(pjoin((path_drive + 'data'),'test_once','test1_labels.npy'))\r\n",
    "\t\telif 'test2' in self.split:\r\n",
    "\t\t\tself.seismic = np.load(pjoin((path_drive + 'data'),'test_once','test2_seismic.npy'))\r\n",
    "\t\t\tself.labels = np.load(pjoin((path_drive + 'data'),'test_once','test2_labels.npy'))\r\n",
    "\t\telse:\r\n",
    "\t\t\traise ValueError('Unknown split.')\r\n",
    "\r\n",
    "\t\tif 'test' not in self.split:\r\n",
    "\t\t\t# We are in train/val mode. Most likely the test splits are not saved yet, \r\n",
    "\t\t\t# so don't attempt to load them.  \r\n",
    "\t\t\tfor split in ['train', 'val', 'train_val']:\r\n",
    "\t\t\t\t# reading the file names for 'train', 'val', 'trainval'\"\"\r\n",
    "\t\t\t\tpath = pjoin((path_drive + 'data'), 'splits', 'section_' + split + '.txt')\r\n",
    "\t\t\t\tfile_list = tuple(open(path, 'r'))\r\n",
    "\t\t\t\tfile_list = [id_.rstrip() for id_ in file_list]\r\n",
    "\t\t\t\tself.sections[split] = file_list\r\n",
    "\t\telif 'test' in split:\r\n",
    "\t\t\t# We are in test mode. Only read the given split. The other one might not \r\n",
    "\t\t\t# be available. \r\n",
    "\t\t\tpath = pjoin((path_drive + 'data'), 'splits', 'section_' + split + '.txt')\r\n",
    "\t\t\tfile_list = tuple(open(path,'r'))\r\n",
    "\t\t\tfile_list = [id_.rstrip() for id_ in file_list]\r\n",
    "\t\t\tself.sections[split] = file_list\r\n",
    "\t\telse:\r\n",
    "\t\t\traise ValueError('Unknown split.')\r\n",
    "\r\n",
    "\r\n",
    "\tdef __len__(self):\r\n",
    "\t\treturn len(self.sections[self.split])\r\n",
    "\r\n",
    "\tdef __getitem__(self, index):\r\n",
    "\r\n",
    "\t\tsection_name = self.sections[self.split][index]\r\n",
    "\t\tdirection, number = section_name.split(sep='_')\r\n",
    "\r\n",
    "\t\tif direction == 'i':\r\n",
    "\t\t\t\tim = self.seismic[int(number),:,:]\r\n",
    "\t\t\t\tlbl = self.labels[int(number),:,:]\r\n",
    "\t\telif direction == 'x':    \r\n",
    "\t\t\t\tim = self.seismic[:,int(number),:]\r\n",
    "\t\t\t\tlbl = self.labels[:,int(number),:]\r\n",
    "\t\t\r\n",
    "\t\tif self.augmentations is not None:\r\n",
    "\t\t\t\tim, lbl = self.augmentations(im, lbl)\r\n",
    "\t\t\t\t\r\n",
    "\t\tif self.is_transform:\r\n",
    "\t\t\t\tim, lbl = self.transform(im, lbl)\r\n",
    "\t\treturn im, lbl\r\n",
    "\r\n",
    "\r\n",
    "\tdef transform(self, img, lbl):\r\n",
    "\t\t\"\"\"\r\n",
    "\t\tTransforma os dados na posição correta e normaliza\r\n",
    "\t\t:parâmetro img: dados da imagem  \r\n",
    "\t\t:parâmetro lbl: dados das labels \r\n",
    "\t\treturn: img(imagem), lbl(label)\r\n",
    "\t\t\"\"\" \r\n",
    "\t\timg -= self.mean\r\n",
    "\r\n",
    "\t\t# to be in the BxCxHxW: \r\n",
    "\t\timg, lbl = img.T, lbl.T\r\n",
    "\r\n",
    "\t\timg = np.array(img)\r\n",
    "\t\tlbl = np.array(lbl)\r\n",
    "\r\n",
    "\t\t#normalização 0-1 (os dados estão entre 1 a -1)\r\n",
    "\t\tscaler = MinMaxScaler(feature_range=(0,1))\r\n",
    "\t\tscaler = scaler.fit(img)\r\n",
    "\t\timg = scaler.fit_transform(img)\r\n",
    "\t\t\t\t\t\t\r\n",
    "\t\treturn img, lbl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def processWeights(image_label):\r\n",
    "    \"\"\"\r\n",
    "    Contabiliza os valores dos pixels por classe para definir o peso\r\n",
    "    :parâmetro image_label: imagem com as labels \r\n",
    "    return: weights (pesos de cada classe na imagem)\r\n",
    "    \"\"\" \r\n",
    "    image_ = image_label\r\n",
    "    (unique, counts) = np.unique(image_, return_counts=True)\r\n",
    "    #weights for each class\r\n",
    "    num_pixels = image_.shape[0] * image_.shape[1] \r\n",
    "    weights_ = [0,0,0,0,0,0]\r\n",
    "    for i in range(len(counts)):\r\n",
    "        weights_[i] = counts[i]/num_pixels\r\n",
    "    \r\n",
    "    return weights_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def resizePotencia2(image, size, flag):\r\n",
    "\t\"\"\"\r\n",
    "\tRedefine o tamanho da imagem\r\n",
    "\t:parâmetro image: imagem\r\n",
    "\t:parâmetro size: \r\n",
    "\t:parâmetro flag: tipo de redefinição\r\n",
    "\t\t\t\t\t- 'preencher': preenche com valores próximos\r\n",
    "\t\t\t\t\t- 'rezize': função do tensorflow que redefine a imagem\r\n",
    "\t\t\t\t\t- '': Copia a imagem para uma imagem quadrada adicionando a classe 0 de background\r\n",
    "\treturn: matriz \r\n",
    "\t\"\"\" \r\n",
    "\tif flag == 'resize':\r\n",
    "\t\treturn tf.image.resize(image, [size,size])\r\n",
    "\r\n",
    "\timage_ = image\r\n",
    "\tresult = np.zeros((size, size))\r\n",
    "\tresult[:image_.shape[0],:image_.shape[1]] = image_[:,:]\r\n",
    "\r\n",
    "\tif flag == 'preencher':\r\n",
    "\t\tfor i in range(0, size):\r\n",
    "\t\t\tfor j in range(image_.shape[1]-1, size):\r\n",
    "\t\t\t\tresult[i][j] = result[i][j-1]\r\n",
    "\r\n",
    "\t\tfor i in range(image_.shape[0]-1, size):\r\n",
    "\t\t\tfor j in range(0, size):\r\n",
    "\t\t\t\tresult[i][j] = result[i-1][j]\r\n",
    "\r\n",
    "\treturn result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def buildingSet(examples_set):\r\n",
    "    # construção de um conjunto, vetor de imagens e labels e seus pesos\r\n",
    "    samples = []\r\n",
    "    samples_labels = []\r\n",
    "    count = 0\r\n",
    "    for i, (imagens, labels) in enumerate(examples_set):\r\n",
    "        image_original, labels_original = imagens, labels\r\n",
    "\r\n",
    "        # Contabiliza a proporção de pixels de casa classe\r\n",
    "        weights_ = processWeights(labels_original)\r\n",
    "        for j in range(len(weights_class)):                \r\n",
    "            weights_class[j] = weights_class[j] + weights_[j] \r\n",
    "    \r\n",
    "        count = count + 1 \r\n",
    "\r\n",
    "        # image_original = resizePotencia2(image_original, 512, 'resize')\r\n",
    "        # labels_original = resizePotencia2(labels_original, 512, 'resize')\r\n",
    "\r\n",
    "        image_original = np.expand_dims(image_original, axis=-1) \r\n",
    "        labels_original = np.expand_dims(labels_original, axis=-1)\r\n",
    "\r\n",
    "        image_original = tf.image.resize(image_original, [256,256])\r\n",
    "        labels_original = tf.image.resize(labels_original, [256,256])  \r\n",
    "\r\n",
    "        samples.append(image_original)\r\n",
    "        samples_labels.append(labels_original)\r\n",
    "\r\n",
    "    for j in range(len(weights_class)):                \r\n",
    "        weights_class[j] = weights_class[j]/count\r\n",
    "\r\n",
    "    return np.array(samples), np.array(samples_labels), np.array(weights_class)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tfDataset(dataset_samples, dataset_labels, num_classes, SHUFFLE_BUFFER_SIZE, BATCH_SIZE):\r\n",
    "\r\n",
    "    # Divide a imagem da label em 6 referente as classes (uma máscara para cada classe)\r\n",
    "    dataset_labels = tf.keras.utils.to_categorical(dataset_labels, num_classes=num_classes)\r\n",
    "    #Tensor com o conjunto de dados X e Y\r\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dataset_samples, dataset_labels))\r\n",
    "    #mantém um buffer size elementos e seleciona aleatoriamente o próximo elemento desse buffer\r\n",
    "    dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\r\n",
    "\r\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fluxo da construção dos dados de treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Argumentos\r\n",
    "path_drive = \"gdrive/My Drive/ColabNotebooks/\"\r\n",
    "BATCH_SIZE = 8\r\n",
    "SHUFFLE_BUFFER_SIZE = 16\r\n",
    "num_classes = 6\r\n",
    "weights_class = [0,0,0,0,0,0]\r\n",
    "\r\n",
    "args = {\r\n",
    "              \"arch\": 'section_deconvnet',\r\n",
    "              \"n_epoch\": 61,\r\n",
    "              \"batch_size\": 8,\r\n",
    "              \"resume\": None,\r\n",
    "              \"clip\": 0.1,\r\n",
    "              \"per_val\": 0.1,\r\n",
    "              \"pretrained\": False,\r\n",
    "              \"aug\": True,\r\n",
    "              \"class_weights\": False,\r\n",
    "            }\r\n",
    "\r\n",
    "\"\"\"1. Load the dataset: Generate the train and validation sets for the model\"\"\"\r\n",
    "#split_train_val(args, per_val=args['per_val'])\r\n",
    "\r\n",
    "\"\"\"2. Load the dataset: object set \"\"\"\r\n",
    "#object to train\r\n",
    "train_set = section_loader(is_transform=True, split='train',)    \r\n",
    "    \r\n",
    "# object to validation\r\n",
    "val_set = section_loader(is_transform=True, split='val',)\r\n",
    "\r\n",
    "\"\"\"3. Dataset: building Set \"\"\"\r\n",
    "#construção do vetor de imagens de treino\r\n",
    "train_samples, train_labels, weights_class = buildingSet(train_set)\r\n",
    "train_samples, train_labels = train_samples[0:200,:,:], train_labels[0:200,:,:]\r\n",
    "\r\n",
    "#construção do vetor de imagens de validação\r\n",
    "val_samples, val_labels, weights_class_validation = buildingSet(val_set)\r\n",
    "val_samples, val_labels = val_samples[0:20,:,:], val_labels[0:20,:,:]\r\n",
    "\r\n",
    "\"\"\"4. Dataset: tf dataset \"\"\"\r\n",
    "# train\r\n",
    "train_dataset = tfDataset(train_samples, train_labels, num_classes, SHUFFLE_BUFFER_SIZE, BATCH_SIZE)\r\n",
    "# Validation\r\n",
    "validation_dataset = tfDataset(val_samples, val_labels, num_classes, SHUFFLE_BUFFER_SIZE, BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Visualizar informações dos dados de treino\r\n",
    "print(\"Dados de treino\")\r\n",
    "print(\"Samples e labels: \", train_samples.shape, train_labels.shape)\r\n",
    "print(\"Dados de validação\")\r\n",
    "print(\"Samples e labels: \",  val_samples.shape, val_labels.shape)\r\n",
    "print(\"Pesos: \" , weights_class)\r\n",
    "\r\n",
    "fig, ax = plt.subplots(1,2)\r\n",
    "ax[0].imshow(np.array(train_samples[0][:,:,0]))\r\n",
    "ax[1].imshow(np.array(train_labels[0][:,:,0]))\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Visualizar informações dos dados TF de treino\r\n",
    "print(\"TF dataset of train: \", train_dataset)\r\n",
    "print(\"TF dataset of validation: \", validation_dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# deletar dados que não serão mais usados: objetos com os conjuntos dos dados\r\n",
    "del train_samples, train_labels, val_samples, val_labels, weights_class_validation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rede Neural"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoder / Decoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def unet_model(input_shape, n_classes):\r\n",
    "\t\"\"\" Define o conjuntode treino e validação\r\n",
    "\r\n",
    "\tParameters:\r\n",
    "\t\tinput_shape ( ): Shape de entrada (imagens)\r\n",
    "\t\tn_classes (Integer): Quantidade de classes\r\n",
    "\r\n",
    "\tReturns: \r\n",
    "\t\tObject: Modelo da rede\r\n",
    "\t\"\"\"\r\n",
    "\r\n",
    "\tinputs = tf.keras.layers.Input(input_shape)\r\n",
    "\tx = inputs\r\n",
    "\r\n",
    "\t# ------------------- Encoder ------------------- #\r\n",
    "\r\n",
    "\t# Block encoder 1\r\n",
    "\tconv_enc_1 = tf.keras.layers.Conv2D(64, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(x)\r\n",
    "\tconv_enc_1 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_1)\r\n",
    "\tconv_enc_1 = tf.keras.layers.Conv2D(64, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_1)\r\n",
    "\tconv_enc_1 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_1)\r\n",
    "\tmax_pool_enc_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv_enc_1)\r\n",
    "\r\n",
    "\t# Block encoder 2\r\n",
    "\tconv_enc_2 = tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(max_pool_enc_1)\r\n",
    "\tconv_enc_2 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_2)\r\n",
    "\tconv_enc_2 = tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_2)\r\n",
    "\tconv_enc_2 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_2)\r\n",
    "\tmax_pool_enc_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv_enc_2)\r\n",
    "\r\n",
    "\t# Block  encoder 3\r\n",
    "\tconv_enc_3 = tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(max_pool_enc_2)\r\n",
    "\tconv_enc_3 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_3)\r\n",
    "\tconv_enc_3 = tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_3)\r\n",
    "\tconv_enc_3 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_3)\r\n",
    "\tconv_enc_3 = tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_3)\r\n",
    "\tconv_enc_3 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_3)\r\n",
    "\tmax_pool_enc_3 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv_enc_3)\r\n",
    "\r\n",
    "\t# Block  encoder 4\r\n",
    "\tconv_enc_4 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(max_pool_enc_3)\r\n",
    "\tconv_enc_4 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_4)\r\n",
    "\tconv_enc_4 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_4)\r\n",
    "\tconv_enc_4 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_4)\r\n",
    "\tconv_enc_4 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_4)\r\n",
    "\tmax_pool_enc_4 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv_enc_4)\r\n",
    "\r\n",
    "\t# Block  encoder 5\r\n",
    "\tconv_enc_5 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(max_pool_enc_4)\r\n",
    "\tconv_enc_5 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_5)\r\n",
    "\tconv_enc_5 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_5)\r\n",
    "\tconv_enc_5 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_5)\r\n",
    "\tconv_enc_5 = tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_5)\r\n",
    "\tmax_pool_enc_5 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv_enc_5)\r\n",
    "\r\n",
    "\t# Block  encoder 6\r\n",
    "\tconv_enc_6 = tf.keras.layers.Conv2D(4096, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(max_pool_enc_5)\r\n",
    "\tconv_enc_6 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_6)\r\n",
    "\r\n",
    "\t# Block  encoder 7\r\n",
    "\tconv_enc_7 = tf.keras.layers.Conv2D(4096, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_6)\r\n",
    "\tconv_enc_7 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_enc_7)\r\n",
    "\t\r\n",
    "\r\n",
    "\t# ------------------- Decoder ------------------- #\r\n",
    "\r\n",
    "\t# Block  decoder 8\r\n",
    "\tconv_dec_8 = tf.keras.layers.Conv2DTranspose(4096, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_enc_7)\r\n",
    "\tconv_dec_8 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_8)\r\n",
    "\r\n",
    "\t# Block  decoder 9\r\n",
    "\tup_dec_9 = tf.keras.layers.UpSampling2D(2)(conv_dec_8)\r\n",
    "\tup_dec_9 = tf.keras.layers.Concatenate()([up_dec_9, conv_enc_5])\r\n",
    "\r\n",
    "\t# Block  decoder 10\r\n",
    "\tconv_dec_10 = tf.keras.layers.Conv2DTranspose(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(up_dec_9)\r\n",
    "\tconv_dec_10 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_10)\r\n",
    "\tconv_dec_10 = tf.keras.layers.Conv2DTranspose(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_dec_10)\r\n",
    "\tconv_dec_10 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_10)\r\n",
    "\tconv_dec_10 = tf.keras.layers.Conv2DTranspose(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_dec_10)\r\n",
    "\tconv_dec_10 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_10)\r\n",
    "\r\n",
    "\t# Block  decoder 11\r\n",
    "\tup_dec_11 = tf.keras.layers.UpSampling2D(2)(conv_dec_10)\r\n",
    "\tup_dec_11 = tf.keras.layers.Concatenate()([up_dec_11, conv_enc_4])\r\n",
    "\r\n",
    "\t# Block  decoder 12\r\n",
    "\tconv_dec_12 = tf.keras.layers.Conv2DTranspose(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(up_dec_11)\r\n",
    "\tconv_dec_12 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_12)\r\n",
    "\tconv_dec_12 = tf.keras.layers.Conv2DTranspose(512, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_dec_12)\r\n",
    "\tconv_dec_12 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_12)\r\n",
    "\tconv_dec_12 = tf.keras.layers.Conv2DTranspose(256, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_dec_12)\r\n",
    "\tconv_dec_12 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_12)\r\n",
    "\r\n",
    "\t# Block  decoder 13\r\n",
    "\tup_dec_13 = tf.keras.layers.UpSampling2D(2)(conv_dec_12)\r\n",
    "\tup_dec_13 = tf.keras.layers.Concatenate()([up_dec_13, conv_enc_3])\r\n",
    "\r\n",
    "\t# Block  decoder 14\r\n",
    "\tconv_dec_14 = tf.keras.layers.Conv2DTranspose(256, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(up_dec_13)\r\n",
    "\tconv_dec_14 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_14)\r\n",
    "\tconv_dec_14 = tf.keras.layers.Conv2DTranspose(256, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_dec_14)\r\n",
    "\tconv_dec_14 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_14)\r\n",
    "\tconv_dec_14 = tf.keras.layers.Conv2DTranspose(128, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_dec_14)\r\n",
    "\tconv_dec_14 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_14)\r\n",
    "\r\n",
    "\t# Block  decoder 15\r\n",
    "\tup_dec_15 = tf.keras.layers.UpSampling2D(2)(conv_dec_14)\r\n",
    "\tup_dec_15 = tf.keras.layers.Concatenate()([up_dec_15, conv_enc_2])\r\n",
    "\r\n",
    "\t# Block  decoder 16\r\n",
    "\tconv_dec_16 = tf.keras.layers.Conv2DTranspose(128, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(up_dec_15)\r\n",
    "\tconv_dec_16 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_16)\r\n",
    "\tconv_dec_16 = tf.keras.layers.Conv2DTranspose(128, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_dec_16)\r\n",
    "\tconv_dec_16 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_16)\r\n",
    "\r\n",
    "\t# Block  decoder 17\r\n",
    "\tup_dec_17 = tf.keras.layers.UpSampling2D(2)(conv_dec_16)\r\n",
    "\tup_dec_17 = tf.keras.layers.Concatenate()([up_dec_17, conv_enc_1])\r\n",
    "\r\n",
    "\t# Block  decoder 18\r\n",
    "\tconv_dec_18 = tf.keras.layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(up_dec_17)\r\n",
    "\tconv_dec_18 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_18)\r\n",
    "\tconv_dec_18 = tf.keras.layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding=\"same\", activation= \"relu\")(conv_dec_18)\r\n",
    "\tconv_dec_18 = tf.keras.layers.BatchNormalization(momentum=0.1,epsilon=1e-05)(conv_dec_18)\r\n",
    "\r\n",
    "\t# Block  decoder 19\r\n",
    "\toutput = tf.keras.layers.Conv2D(n_classes, kernel_size=1, padding=\"same\", activation='softmax')(conv_dec_18)  \r\n",
    "\r\n",
    "\tmodel_unet = tf.keras.models.Model(inputs, output)\r\n",
    "\tmodel_unet.summary()\r\n",
    "\r\n",
    "\treturn model_unet"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('mestrado': conda)"
  },
  "interpreter": {
   "hash": "447cc6f42bbc2aea3361993c39d6f6c3959bdf1889010beb1442d5334007d2b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}